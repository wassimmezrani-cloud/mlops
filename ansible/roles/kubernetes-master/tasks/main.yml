---
# Kubernetes master node configuration

- name: Validate required variables
  assert:
    that:
      - k8s_version is defined
      - k8s_version is match("^\d+\.\d+\.\d+$")
      - k8s_control_plane_endpoint is defined
      - pod_network_cidr is defined
      - service_cidr is defined
    fail_msg: "Required Kubernetes variables are not properly defined"

- name: Install containerd.io
  apt:
    name: containerd.io
    state: present
    update_cache: true

- name: Create containerd configuration directory
  file:
    path: /etc/containerd
    state: directory
    mode: '0755'

- name: Generate containerd default configuration
  shell: containerd config default > /etc/containerd/config.toml
  args:
    creates: /etc/containerd/config.toml

- name: Configure containerd to use systemd cgroup
  lineinfile:
    path: /etc/containerd/config.toml
    regexp: '^\s*SystemdCgroup\s*='
    line: '            SystemdCgroup = true'
    backup: true
  notify: restart containerd

- name: Start and enable containerd
  systemd:
    name: containerd
    state: started
    enabled: true

- name: Add Kubernetes apt key
  apt_key:
    url: https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key
    state: present

- name: Add Kubernetes repository
  apt_repository:
    repo: "deb https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /"
    state: present
    filename: kubernetes

- name: Install specific Kubernetes components
  apt:
    name:
      - kubelet={{ k8s_version }}-1.1
      - kubeadm={{ k8s_version }}-1.1
      - kubectl={{ k8s_version }}-1.1
    state: present
    update_cache: true

- name: Hold Kubernetes packages
  dpkg_selections:
    name: "{{ item }}"
    selection: hold
  loop:
    - kubelet
    - kubeadm
    - kubectl

- name: Start and enable kubelet
  systemd:
    name: kubelet
    state: started
    enabled: true

- name: Check if cluster is already initialized
  stat:
    path: /etc/kubernetes/admin.conf
  register: k8s_admin_conf

- name: Initialize Kubernetes cluster (only on first master)
  command: >
    kubeadm init
    --apiserver-advertise-address={{ ansible_host }}
    --pod-network-cidr={{ pod_network_cidr }}
    --service-cidr={{ service_cidr }}
    --control-plane-endpoint={{ k8s_control_plane_endpoint }}
    --upload-certs
    --kubernetes-version=v{{ k8s_version }}
  when: 
    - inventory_hostname == groups['k8s-masters'][0]
    - not k8s_admin_conf.stat.exists
  register: kubeadm_init

- name: Generate join token for cluster
  command: kubeadm token create --print-join-command
  when: inventory_hostname == groups['k8s-masters'][0]
  register: join_command

- name: Generate certificate key for control plane
  command: kubeadm init phase upload-certs --upload-certs
  when: inventory_hostname == groups['k8s-masters'][0]
  register: certificate_key_output

- name: Extract certificate key
  set_fact:
    certificate_key: "{{ certificate_key_output.stdout_lines[-1] }}"
  when: 
    - inventory_hostname == groups['k8s-masters'][0] 
    - certificate_key_output.stdout_lines is defined
    - certificate_key_output.stdout_lines | length > 0

- name: Extract join command components
  set_fact:
    kubeadm_token: "{{ join_command.stdout.split('--token ')[1].split(' ')[0] }}"
    ca_cert_hash: "{{ join_command.stdout.split('--discovery-token-ca-cert-hash ')[1].split(' ')[0] }}"
  when: 
    - inventory_hostname == groups['k8s-masters'][0] 
    - join_command.stdout is defined
    - "'--token ' in join_command.stdout"
    - "'--discovery-token-ca-cert-hash ' in join_command.stdout"

- name: Check if additional masters are already joined
  stat:
    path: /etc/kubernetes/kubelet.conf
  register: kubelet_conf

- name: Join additional master nodes to cluster
  command: >
    kubeadm join {{ k8s_control_plane_endpoint }}
    --token {{ hostvars[groups['k8s-masters'][0]]['kubeadm_token'] }}
    --discovery-token-ca-cert-hash {{ hostvars[groups['k8s-masters'][0]]['ca_cert_hash'] }}
    --control-plane
    --certificate-key {{ hostvars[groups['k8s-masters'][0]]['certificate_key'] }}
    --apiserver-advertise-address={{ ansible_host }}
  when: 
    - inventory_hostname != groups['k8s-masters'][0]
    - not kubelet_conf.stat.exists
  register: kubeadm_join_master

- name: Create .kube directory for user
  file:
    path: /home/{{ ansible_user }}/.kube
    state: directory
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"
    mode: '0755'

- name: Copy admin.conf to user's kube config
  copy:
    src: /etc/kubernetes/admin.conf
    dest: /home/{{ ansible_user }}/.kube/config
    remote_src: true
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"
    mode: '0644'
  when: inventory_hostname == groups['k8s-masters'][0]

- name: Check if Flannel CNI is already installed
  command: kubectl get daemonset -n kube-flannel kube-flannel-ds
  become_user: "{{ ansible_user }}"
  register: flannel_check
  failed_when: false
  changed_when: false
  when: inventory_hostname == groups['k8s-masters'][0]

- name: Install Flannel CNI (only on first master)
  command: kubectl apply -f {{ flannel_url }}
  become_user: "{{ ansible_user }}"
  when: 
    - inventory_hostname == groups['k8s-masters'][0]
    - flannel_check.rc != 0

- name: Check if NGINX Ingress Controller is already installed
  command: kubectl get deployment -n ingress-nginx ingress-nginx-controller
  become_user: "{{ ansible_user }}"
  register: ingress_check
  failed_when: false
  changed_when: false
  when: inventory_hostname == groups['k8s-masters'][0]

- name: Install NGINX Ingress Controller (only on first master)
  command: kubectl apply -f {{ ingress_url }}
  become_user: "{{ ansible_user }}"
  when: 
    - inventory_hostname == groups['k8s-masters'][0]
    - ingress_check.rc != 0

- name: Wait for ingress controller to be ready
  command: kubectl wait --namespace ingress-nginx --for=condition=ready pod --selector=app.kubernetes.io/component=controller --timeout=300s
  become_user: "{{ ansible_user }}"
  when: 
    - inventory_hostname == groups['k8s-masters'][0]
    - ingress_check.rc != 0